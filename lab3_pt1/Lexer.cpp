/*

Elias Sims, Section 1, elisims@byu.edu
Lab 1: Lexical Analyzer

*/

#include <cstdlib>
#include <iostream>

#include "Lexer.h"
#include "Token.h"

using namespace std;

/*Catches the call from main.cpp, initiates all other functinality of Lab 1*/
vector<Token> Lexer::generateTokens() {

	while (!file.eof()) {	//Runs through entire file
		getToken();
	}

	if (tokenVec.back().getIdentifier() != "EOF") {	//Ensures final output has an "EOF" token at the end
		tokenVec.push_back(Token(lineNum, "", "EOF"));
	}

	return tokenVec;
}

/*Handles the functionality for the "Whitespace" portion of Lab 1*/
void Lexer::whiteSpace() {
	while (isspace(curToken)) {	//Utilizes "isspace()" functionality to fulfill requirements
		if (!file.eof()) {
			if (curToken == '\n') {
				lineNum++;
			}

			if (isalpha(file.peek())) {
				curToken = file.get();
				break;
			}

			curToken = file.get();
		}

		else {
			break;
		}
	}
}

/*Handles the functionality for the ":" and ":-" portion of Lab 1*/
void Lexer::colonDash() {

	if (file.peek() == '-') {	//Checks one char ahead, if "-" is seen, adds ":-" to vector
		file.get();
		tokenVec.push_back(Token(tempLineNum, ":-", "COLON_DASH"));
	}

	else {	//If "peek" function doesn't find "-", ":" alone is added to vector
		tokenVec.push_back(Token(tempLineNum, ":", "COLON"));
	}
}

/*Handles the functionality for the "comment" portion of Lab 1*/
void Lexer::comment() {
	string comment;
	comment += curToken;
	
	if (file.peek() == '|') {	//Catches the multiline comments
		//cout << "OH NOOO";	//Outputs current location in program (debugging)
		comment += file.get();
		while (file.peek() != '#' && (!file.eof())) {
			if (file.peek() == '\n') {
				if (file.peek() == '\r') {	//Checks and catches the return carriage error
					break;
				}
				lineNum++;
			}
			comment += file.get();
		}

		if (comment.back() != '|') {
			if (lineNum == tempLineNum) {
				tokenVec.push_back(Token(tempLineNum, comment, "COMMENT"));
			}
			else
			{
				tokenVec.push_back(Token(tempLineNum, comment, "UNDEFINED"));
			}
		}

		if (comment.back() == '|' && (!file.eof())) {
			comment += file.get();
			tokenVec.push_back(Token(tempLineNum, comment, "COMMENT"));
		}

		else {
			tokenVec.push_back(Token(tempLineNum, comment, "UNDEFINED"));
		}
	}

	else {
		while (file.peek() != '\n' /*&& '\r' */&& (!file.eof())) {
			if (file.peek() == '\r') {	//Checks and catches the return carriage error
				break;
			}
			else {
				comment += file.get();
			}
		}
		tokenVec.push_back(Token(tempLineNum, comment, "COMMENT"));

	}

}

/*Handles the functionality for the "Strings" portion of Lab 1*/
void Lexer::strings() {
	string tempString;
	tempString += curToken;

	while (!file.eof()) {
		tempString += file.get();
		//if (file.peek() == '\n' /*&& '\r'*/) {
		//	if (file.peek() != '\r') {	//Checks and catches the return carriage error
		//		lineNum++;
		//	}
		//	else {
		//		break;
		//	}
		//}
		if (tempString.back() == '\n' /*&& '\r'*/) {
			if (tempString.back() != '\r') {	//Checks and catches the return carriage error
				lineNum++;
			}
			else {
				break;
			}
		}

		if (tempString.back() == '\'') {	//If a '\'' is found at the end of the string-
			if (file.peek() == '\'') {		//checks if next char is '\'' as well, if so,
				tempString += file.get();	//the string function is continued, thus 
				continue;					//fulfilling the requirement.
			}
			else {
				break;
			}
		}

		if (file.peek() == file.eof()) {
			break;
		}
	}

	if (tempString.back() != '\'') {
		tokenVec.push_back(Token(tempLineNum, tempString, "UNDEFINED"));
	}

	else {
		tokenVec.push_back(Token(tempLineNum, tempString, "STRING"));
	}
}

/*Handles the default case of the Switch Statement*/
void Lexer::defaultSort() {

	if (file.eof()) {
		tokenVec.push_back(Token(tempLineNum, "", "EOF"));
		return;
	}

	string tempString;
	tempString += curToken;

	if (!isalpha(curToken)) {
		tokenVec.push_back(Token(tempLineNum, tempString, "UNDEFINED"));
		return;
	}

	while (isalpha(file.peek()) || isdigit(file.peek())) {
		tempString += file.get();
	}

	sortWord(tempString);
}

void Lexer::sortWord(string triggerWord) {
	if (triggerWord == "Schemes") {
		tokenVec.push_back(Token(tempLineNum, triggerWord, "SCHEMES"));
	}

	else if (triggerWord == "Facts") {
		tokenVec.push_back(Token(tempLineNum, triggerWord, "FACTS"));
	}

	else if (triggerWord == "Rules") {
		tokenVec.push_back(Token(tempLineNum, triggerWord, "RULES"));
	}

	else if (triggerWord == "Queries") {
		tokenVec.push_back(Token(tempLineNum, triggerWord, "QUERIES"));
	}

	else {
		tokenVec.push_back(Token(tempLineNum, triggerWord, "ID"));
	}
}

/*Handles all cases generated by the input file using a Switch Statement*/
Token Lexer::getToken() {
	//cout << "LexicalAnalyzer::getToken()" << endl; //Outputs current position (debugging)
	if (file.eof()) {
		return tokenVec.back();
	}

	curToken = file.get();
	whiteSpace();
	tempLineNum = lineNum;

	//cout << "switch(" << holder << ')' << endl; //Outputs current position (debugging)
	switch (curToken) {
	case ',': {
		//cout << "	case ',':" << endl; //Outputs current position (debugging)
		tokenVec.push_back(Token(tempLineNum, ",", "COMMA"));
		return tokenVec.back();
	}

	case '.': {
		//cout << "	case '.':" << endl; //Outputs current position (debugging)
		tokenVec.push_back(Token(tempLineNum, ".", "PERIOD"));
		return tokenVec.back();
	}

	case '?': {
		//cout << "	case '?':" << endl; //Outputs current position (debugging)
		tokenVec.push_back(Token(tempLineNum, "?", "Q_MARK"));
		return tokenVec.back();
	}

	case '(': {
		//cout << "	case '(':" << endl; //Outputs current position (debugging)
		tokenVec.push_back(Token(tempLineNum, "(", "LEFT_PAREN"));
		return tokenVec.back();
	}

	case ')': {
		//cout << "	case ')':" << endl; //Outputs current position (debugging)
		tokenVec.push_back(Token(tempLineNum, ")", "RIGHT_PAREN"));
		return tokenVec.back();
	}

	case '+': {
		//cout << "	case '+':" << endl; //Outputs current position (debugging)
		tokenVec.push_back(Token(tempLineNum, "+", "ADD"));
		return tokenVec.back();
	}

	case '*': {
		//cout << "	case '*':" << endl; //Outputs current position (debugging)
		tokenVec.push_back(Token(tempLineNum, "*", "MULTIPLY"));
		return tokenVec.back();
	}

	case ':': {
		//cout << "	case ':':" << endl; //Outputs current position (debugging)
		colonDash();
		return tokenVec.back();
	}

	case '#': {
		//cout << "	case '#':" << endl; //Outputs current position (debugging)
		comment();
		return tokenVec.back();
	}

	case '\'': {
		//cout << "	case '\'':" << endl; //Outputs current position (debugging)
		strings();
		return tokenVec.back();
	}

	default: {
		//cout << "	default:" << endl; //Outputs current position (debugging)
		defaultSort();
		return tokenVec.back();
	}
	}
}